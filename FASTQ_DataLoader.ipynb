{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "td6Tq9M3y6xw"
      ],
      "authorship_tag": "ABX9TyNOPkH6GLs3KInuIBGu16Rz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andrkech/GENERATIVE-METHODS-IN-GENOMICS/blob/main/FASTQ_DataLoader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the Dataset."
      ],
      "metadata": {
        "id": "b7OHL-Cv1dkL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Connect with Google Drive."
      ],
      "metadata": {
        "id": "I0yGyfaTt6n3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "PSDgVlCuuDbP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33e219b8-7a3c-4ea5-9d73-19da02e70243"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries."
      ],
      "metadata": {
        "id": "DKE1gaFlycvW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import zipfile\n",
        "import tarfile\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans"
      ],
      "metadata": {
        "id": "O1oBS28VyDg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Unzip the dataset folder and import it into the Colab notebook."
      ],
      "metadata": {
        "id": "MLiiBeYtyj73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_or_create_zip(source_path, extract_path):\n",
        "    # Check if the source path is a directory\n",
        "    if os.path.isdir(source_path):\n",
        "        # Create a ZIP file from the directory contents\n",
        "        shutil.make_archive(extract_path, \"zip\", source_path)\n",
        "        print(f\"Created ZIP file from directory: {source_path}\")\n",
        "\n",
        "    elif os.path.isfile(source_path) and source_path.lower().endswith('.zip'):\n",
        "        # Extract the existing ZIP file\n",
        "        with zipfile.ZipFile(source_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(extract_path)\n",
        "            print(f\"Extraction completed successfully: {source_path}\")\n",
        "\n",
        "    else:\n",
        "        print(f\"Error: Invalid source path '{source_path}'. Must be a directory or a ZIP file.\")"
      ],
      "metadata": {
        "id": "Dfq3unrswb4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define source and extraction paths\n",
        "source_path = \"/content/drive/MyDrive/THESIS_KECHAGIAS/DATA/DATASET/FASTQ_FILES.zip\"\n",
        "extract_path = \"/content/fastq_dataset\"\n",
        "\n",
        "# Extract or create ZIP file based on source path\n",
        "extract_or_create_zip(source_path, extract_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKr3_jFd6p_Z",
        "outputId": "1c317541-fede-4929-ff32-631caa377b65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extraction completed successfully: /content/drive/MyDrive/BIOINFORMATICS/THESIS_KECHAGIAS/DATA/DATASET/FASTQ_FILES.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extract the inner compressed folders, if needed."
      ],
      "metadata": {
        "id": "td6Tq9M3y6xw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_compressed_files(source_path, extract_dir):\n",
        "    # Check if the source path exists\n",
        "    if not os.path.exists(source_path):\n",
        "        print(f\"Error: Source path '{source_path}' not found.\")\n",
        "        return\n",
        "\n",
        "    # Create the extraction directory if it doesn't exist\n",
        "    os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "    # Iterate through all files in the directory\n",
        "    for file in os.listdir(source_path):\n",
        "        file_path = os.path.join(source_path, file)\n",
        "\n",
        "        # Extract compressed files\n",
        "        if file.endswith('.zip'):\n",
        "            extract_file(file_path, extract_dir)\n",
        "\n",
        "        elif file.endswith('.tar'):\n",
        "            extract_file(file_path, extract_dir)\n",
        "\n",
        "def extract_file(source_path, extract_dir):\n",
        "    try:\n",
        "        # Get the file extension\n",
        "        file_extension = os.path.splitext(source_path)[1].lower()\n",
        "\n",
        "        # Extract based on file type\n",
        "        if file_extension == '.zip':\n",
        "            with zipfile.ZipFile(source_path, 'r') as zip_ref:\n",
        "                zip_ref.extractall(extract_dir)\n",
        "\n",
        "        elif file_extension == '.tar':\n",
        "            with tarfile.open(source_path, 'r') as tar_ref:\n",
        "                tar_ref.extractall(extract_dir)\n",
        "\n",
        "        print(f\"Extraction completed successfully: {source_path}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting {source_path}: {e}\")"
      ],
      "metadata": {
        "id": "g_4SsVflK7ZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the compressed file\n",
        "extract_compressed_files(extract_path, extract_path)"
      ],
      "metadata": {
        "id": "X-NAniYe11Ex",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8d6b2a0-3180-439b-f9c6-80cd484c45a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extraction completed successfully: /content/fastq_dataset/FASTQ_FILES.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the DataLoader."
      ],
      "metadata": {
        "id": "CdfH2RON1p9F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries."
      ],
      "metadata": {
        "id": "Y-vkJA4WBq_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import Sequence\n",
        "!pip install -q Bio\n",
        "from Bio import SeqIO"
      ],
      "metadata": {
        "id": "uRAKLBXVAVwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize the Dataset."
      ],
      "metadata": {
        "id": "-W77SXOyB0ZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = \"/content/fastq_dataset\"\n",
        "directory_paths = []\n",
        "\n",
        "for dir_name in os.listdir(dataset_path):\n",
        "    dir_path = os.path.join(dataset_path, dir_name)\n",
        "\n",
        "    if dir_path.endswith('fastq'):\n",
        "        directory_paths.append(dir_path)\n",
        "\n",
        "print(directory_paths)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgUhOpRrBmEp",
        "outputId": "09ce06e2-7c56-4ec7-e63b-ac0d84456570"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/fastq_dataset/ERR5960500_2.fastq', '/content/fastq_dataset/ERR5885031_1.fastq', '/content/fastq_dataset/ERR5885024_2.fastq', '/content/fastq_dataset/ERR5885026_2.fastq', '/content/fastq_dataset/ERR6608944_2.fastq', '/content/fastq_dataset/ERR6155196_1.fastq', '/content/fastq_dataset/ERR5885029_1.fastq', '/content/fastq_dataset/ERR6608942_2.fastq', '/content/fastq_dataset/ERR6155195_1.fastq', '/content/fastq_dataset/ERR5960498_2.fastq', '/content/fastq_dataset/ERR5885030_2.fastq', '/content/fastq_dataset/ERR5960498_1.fastq', '/content/fastq_dataset/ERR6155196_2.fastq', '/content/fastq_dataset/ERR5885024_1.fastq', '/content/fastq_dataset/ERR6053338_2.fastq', '/content/fastq_dataset/ERR5885033_2.fastq', '/content/fastq_dataset/ERR5885028_1.fastq', '/content/fastq_dataset/ERR5885027_1.fastq', '/content/fastq_dataset/ERR6608942_1.fastq', '/content/fastq_dataset/ERR5885025_2.fastq', '/content/fastq_dataset/ERR6053337_1.fastq', '/content/fastq_dataset/ERR5885031_2.fastq', '/content/fastq_dataset/ERR6155194_2.fastq', '/content/fastq_dataset/ERR5885033_1.fastq', '/content/fastq_dataset/ERR5885023_2.fastq', '/content/fastq_dataset/ERR5885023_1.fastq', '/content/fastq_dataset/ERR6053338_1.fastq', '/content/fastq_dataset/ERR6053337_2.fastq', '/content/fastq_dataset/ERR6053339_1.fastq', '/content/fastq_dataset/ERR5885026_1.fastq', '/content/fastq_dataset/ERR5885028_2.fastq', '/content/fastq_dataset/ERR6608943_1.fastq', '/content/fastq_dataset/ERR5885025_1.fastq', '/content/fastq_dataset/ERR5885029_2.fastq', '/content/fastq_dataset/ERR5960500_1.fastq', '/content/fastq_dataset/ERR6155195_2.fastq', '/content/fastq_dataset/ERR5885027_2.fastq', '/content/fastq_dataset/ERR5960499_2.fastq', '/content/fastq_dataset/ERR6155194_1.fastq', '/content/fastq_dataset/ERR6608944_1.fastq', '/content/fastq_dataset/ERR5885032_2.fastq', '/content/fastq_dataset/ERR5885030_1.fastq', '/content/fastq_dataset/ERR5885032_1.fastq', '/content/fastq_dataset/ERR6608943_2.fastq', '/content/fastq_dataset/ERR6053339_2.fastq', '/content/fastq_dataset/ERR5960499_1.fastq']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a DataLoader class."
      ],
      "metadata": {
        "id": "OgcNWLQi2OJk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FSjPnKG_ZFZP"
      },
      "outputs": [],
      "source": [
        "class FastqDataset(Sequence):\n",
        "    def __init__(self, data_dir, batch_size=32, shuffle=True):\n",
        "        self.data_dir = data_dir\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.file_list = self.get_file_list()\n",
        "        self.indexes =  list(range(len(self.file_list)))\n",
        "        if self.file_list:\n",
        "            random.shuffle(self.indexes)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list) // self.batch_size\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        batch_indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "        batch_files = [self.file_list[i] for i in batch_indexes]\n",
        "        batch_data = self.load_batch(batch_files)\n",
        "\n",
        "        return batch_data\n",
        "\n",
        "    def get_file_list(self):\n",
        "        file_list = []\n",
        "        for filename in os.listdir(self.data_dir):\n",
        "            if filename.endswith(\".fastq\"):\n",
        "                file_path = os.path.join(self.data_dir, filename)\n",
        "                file_list.append(file_path)\n",
        "\n",
        "        return file_list\n",
        "\n",
        "\n",
        "    def load_batch(self, batch_files):\n",
        "        batch_data = []\n",
        "        for file_path in batch_files:\n",
        "            reads, qualities = self.parse_fastq(file_path)\n",
        "            batch_data.extend(zip(reads, qualities))\n",
        "        return batch_data\n",
        "\n",
        "    def parse_fastq(self, fiel_path):\n",
        "        reads, qualities = [], []\n",
        "\n",
        "        for record in SeqIO.parse(file_path, 'fastq')\n",
        "            reads.append(str( record.seq))\n",
        "            qualities.append(record.letter_annotations['phred_quality'])\n",
        "\n",
        "        return  reads, qualities"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define data directory containing FASTQ files\n",
        "data_dir = '/content/fastq_dataset'\n",
        "\n",
        "# Create an instance of the custom dataset\n",
        "dataset = FastqDataset(data_dir)\n",
        "\n",
        "# Example usage of the dataset\n",
        "for batch_data in dataset:\n",
        "    # Process batch_data as needed\n",
        "    print(\"Batch Size:\", len(batch_data))"
      ],
      "metadata": {
        "id": "jm6Gy1xmj3wK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}