{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "td6Tq9M3y6xw",
        "Y-vkJA4WBq_S"
      ],
      "authorship_tag": "ABX9TyPdUNn2JEqgP34cWZZN5Ynx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andrkech/GENERATIVE-METHODS-IN-GENOMICS/blob/main/FASTQ_DataLoader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the Dataset."
      ],
      "metadata": {
        "id": "b7OHL-Cv1dkL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Connect with Google Drive."
      ],
      "metadata": {
        "id": "I0yGyfaTt6n3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "PSDgVlCuuDbP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe1fc9f5-70b4-4c7e-86d6-0d8c8e801914"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries."
      ],
      "metadata": {
        "id": "DKE1gaFlycvW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import zipfile\n",
        "import tarfile\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans"
      ],
      "metadata": {
        "id": "O1oBS28VyDg5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Unzip the dataset folder and import it into the Colab notebook."
      ],
      "metadata": {
        "id": "MLiiBeYtyj73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_or_create_zip(source_path, extract_path):\n",
        "    # Check if the source path is a directory\n",
        "    if os.path.isdir(source_path):\n",
        "        # Create a ZIP file from the directory contents\n",
        "        shutil.make_archive(extract_path, \"zip\", source_path)\n",
        "        print(f\"Created ZIP file from directory: {source_path}\")\n",
        "\n",
        "    elif os.path.isfile(source_path) and source_path.lower().endswith('.zip'):\n",
        "        # Extract the existing ZIP file\n",
        "        with zipfile.ZipFile(source_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(extract_path)\n",
        "            print(f\"Extraction completed successfully: {source_path}\")\n",
        "\n",
        "    else:\n",
        "        print(f\"Error: Invalid source path '{source_path}'. Must be a directory or a ZIP file.\")"
      ],
      "metadata": {
        "id": "Dfq3unrswb4F"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define source and extraction paths\n",
        "source_path = \"/content/drive/MyDrive/BIOINFORMATICS/THESIS_KECHAGIAS/DATA/DATASET/FASTQ_FILES.zip\"\n",
        "extract_path = \"/content/fastq_dataset\"\n",
        "\n",
        "# Extract or create ZIP file based on source path\n",
        "extract_or_create_zip(source_path, extract_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKr3_jFd6p_Z",
        "outputId": "668ea922-b91a-4c80-ff2b-fd58d73d61ca"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extraction completed successfully: /content/drive/MyDrive/BIOINFORMATICS/THESIS_KECHAGIAS/DATA/DATASET/FASTQ_FILES.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extract the inner compressed folders, if needed."
      ],
      "metadata": {
        "id": "td6Tq9M3y6xw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_compressed_files(source_path, extract_dir):\n",
        "    # Check if the source path exists\n",
        "    if not os.path.exists(source_path):\n",
        "        print(f\"Error: Source path '{source_path}' not found.\")\n",
        "        return\n",
        "\n",
        "    # Create the extraction directory if it doesn't exist\n",
        "    os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "    # Iterate through all files in the directory\n",
        "    for file in os.listdir(source_path):\n",
        "        file_path = os.path.join(source_path, file)\n",
        "\n",
        "        # Extract compressed files\n",
        "        if file.endswith('.zip'):\n",
        "            extract_file(file_path, extract_dir)\n",
        "\n",
        "        elif file.endswith('.tar'):\n",
        "            extract_file(file_path, extract_dir)\n",
        "\n",
        "def extract_file(source_path, extract_dir):\n",
        "    try:\n",
        "        # Get the file extension\n",
        "        file_extension = os.path.splitext(source_path)[1].lower()\n",
        "\n",
        "        # Extract based on file type\n",
        "        if file_extension == '.zip':\n",
        "            with zipfile.ZipFile(source_path, 'r') as zip_ref:\n",
        "                zip_ref.extractall(extract_dir)\n",
        "\n",
        "        elif file_extension == '.tar':\n",
        "            with tarfile.open(source_path, 'r') as tar_ref:\n",
        "                tar_ref.extractall(extract_dir)\n",
        "\n",
        "        print(f\"Extraction completed successfully: {source_path}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting {source_path}: {e}\")"
      ],
      "metadata": {
        "id": "g_4SsVflK7ZA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0abdcd1f-4b52-4469-990c-21d4637263e4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extraction completed successfully: /content/fastq_dataset/FASTQ_FILES.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the compressed file\n",
        "extract_compressed_files(extract_path, extract_path)"
      ],
      "metadata": {
        "id": "X-NAniYe11Ex",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c04a49f4-359d-4090-8030-cf406d433399"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extraction completed successfully: /content/fastq_dataset/FASTQ_FILES.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the DataLoader."
      ],
      "metadata": {
        "id": "CdfH2RON1p9F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries."
      ],
      "metadata": {
        "id": "Y-vkJA4WBq_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "!pip install Bio\n",
        "from Bio import SeqIO"
      ],
      "metadata": {
        "id": "uRAKLBXVAVwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize the Dataset."
      ],
      "metadata": {
        "id": "-W77SXOyB0ZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = \"/content/fastq_dataset\"\n",
        "directory_paths = []\n",
        "\n",
        "for dir_name in os.listdir(dataset_path):\n",
        "    dir_path = os.path.join(dataset_path, dir_name)\n",
        "\n",
        "    if dir_path.endswith('fastq'):\n",
        "        directory_paths.append(dir_path)\n",
        "\n",
        "print(directory_paths)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgUhOpRrBmEp",
        "outputId": "9a570533-a1da-4350-eb92-ceedc537360a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/fastq_dataset/ERR5885031_2.fastq', '/content/fastq_dataset/ERR5885026_2.fastq', '/content/fastq_dataset/ERR5960500_1.fastq', '/content/fastq_dataset/ERR5885026_1.fastq', '/content/fastq_dataset/ERR6053338_2.fastq', '/content/fastq_dataset/ERR6053339_2.fastq', '/content/fastq_dataset/ERR6053337_1.fastq', '/content/fastq_dataset/ERR6608944_1.fastq', '/content/fastq_dataset/ERR5885027_2.fastq', '/content/fastq_dataset/ERR5885033_2.fastq', '/content/fastq_dataset/ERR5960499_2.fastq', '/content/fastq_dataset/ERR6155194_2.fastq', '/content/fastq_dataset/ERR6155194_1.fastq', '/content/fastq_dataset/ERR5885024_1.fastq', '/content/fastq_dataset/ERR6608942_1.fastq', '/content/fastq_dataset/ERR5885030_1.fastq', '/content/fastq_dataset/ERR5885031_1.fastq', '/content/fastq_dataset/ERR5885028_1.fastq', '/content/fastq_dataset/ERR5960500_2.fastq', '/content/fastq_dataset/ERR5885025_1.fastq', '/content/fastq_dataset/ERR5885032_2.fastq', '/content/fastq_dataset/ERR5885025_2.fastq', '/content/fastq_dataset/ERR6053339_1.fastq', '/content/fastq_dataset/ERR5885027_1.fastq', '/content/fastq_dataset/ERR5885030_2.fastq', '/content/fastq_dataset/ERR6155195_2.fastq', '/content/fastq_dataset/ERR6155196_1.fastq', '/content/fastq_dataset/ERR6053338_1.fastq', '/content/fastq_dataset/ERR6608943_2.fastq', '/content/fastq_dataset/ERR5885023_2.fastq', '/content/fastq_dataset/ERR5960498_1.fastq', '/content/fastq_dataset/ERR5885024_2.fastq', '/content/fastq_dataset/ERR5960498_2.fastq', '/content/fastq_dataset/ERR5885029_1.fastq', '/content/fastq_dataset/ERR6608944_2.fastq', '/content/fastq_dataset/ERR6608942_2.fastq', '/content/fastq_dataset/ERR5885032_1.fastq', '/content/fastq_dataset/ERR6608943_1.fastq', '/content/fastq_dataset/ERR5885023_1.fastq', '/content/fastq_dataset/ERR6155196_2.fastq', '/content/fastq_dataset/ERR5960499_1.fastq', '/content/fastq_dataset/ERR6155195_1.fastq', '/content/fastq_dataset/ERR5885033_1.fastq', '/content/fastq_dataset/ERR5885028_2.fastq', '/content/fastq_dataset/ERR5885029_2.fastq', '/content/fastq_dataset/ERR6053337_2.fastq']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a Dataset Class."
      ],
      "metadata": {
        "id": "QwLkq8UcBwZo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FASTQDataset(Dataset):\n",
        "    def __init__(self, file_paths):\n",
        "        self.file_paths = file_paths\n",
        "        self.data = []\n",
        "        self._load_data()\n",
        "\n",
        "    def _load_data(self):\n",
        "        for file_path in self.file_paths:\n",
        "            for record in SeqIO.parse(file_path, \"fastq\"):\n",
        "                sequence = str(record.seq)\n",
        "                quality_scores = record.letter_annotations[\"phred_quality\"]\n",
        "                self.data.append({'sequence': sequence, 'quality_scores': quality_scores})\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]"
      ],
      "metadata": {
        "id": "M6pyhamPAOE1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a DataLoader class."
      ],
      "metadata": {
        "id": "OgcNWLQi2OJk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "FSjPnKG_ZFZP"
      },
      "outputs": [],
      "source": [
        "class FASTQ_DataLoader:\n",
        "    def __init__(self, data_dir, batch_size, seq_length):\n",
        "        self.data_dir = data_dir\n",
        "        self.batch_size = batch_size\n",
        "        self.seq_length = seq_length\n",
        "\n",
        "        self.fastq_files = [f for f in os.listdir(data_dir)]\n",
        "\n",
        "    def load_batch(self):\n",
        "        batch_files = np.random.choice(self.fastq_files, size=self.batch_size, replace=False)\n",
        "        batch_sequences = []\n",
        "        batch_quality_scores = []\n",
        "\n",
        "        for file in batch_files:\n",
        "            file_path = os.path.join(self.data_dir, file)\n",
        "            with open(file_path, 'r') as f:\n",
        "                seq, qs = self.extract_seq_and_qs(f)\n",
        "\n",
        "            seq = self.pad_or_truncate(seq, self.seq_length)\n",
        "\n",
        "            batch_sequences.append(seq)\n",
        "            batch_quality_scores.append(qs)\n",
        "\n",
        "        return np.array(batch_sequences), np.array(batch_quality_scores)\n",
        "\n",
        "    def extract_seq_and_qs(self, fastq_file):\n",
        "        # You need to implement this method based on your specific data format\n",
        "        # It should read the FASTQ file and extract sequence (seq) and quality scores (qs)\n",
        "        pass\n",
        "\n",
        "    def pad_or_truncate(self, seq, target_length):\n",
        "        # You need to implement this method based on your requirements\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make a DataLoader object to load the sequence and quality scores batches."
      ],
      "metadata": {
        "id": "LDY6NqY1107M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR = \"/content/fastq_dataset/\"\n",
        "BATCH_SIZE = 16\n",
        "SEQ_LENGTH = 100  # Replace with your desired sequence length\n",
        "dna_loader = FASTQ_DataLoader(DATA_DIR, BATCH_SIZE, SEQ_LENGTH)\n",
        "\n",
        "batch_sequences, batch_quality_scores = dna_loader.load_batch()\n",
        "\n",
        "print(\"Batches loaded successfully.\")"
      ],
      "metadata": {
        "id": "jDdXMb95GWZp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}